#+TITLE: Franka Sim Notes
#+AUTHOR: Ahalya Prabhakar
* Needs to Show
1. Measurement Model learning
2. Learning what the "object" is 
3. Be able to generate new image conditioned on robot state of object
4. some kind of object + measurement model combined learning
   1. use softmax to separate which object it is based on input and predict all other views of object
5. optional: should it also *learn* the object location too? i.e., keep the same object but move the
object location around
6. 
* General (ideal) problem setup
Starting with: some object on tray (always placed in center of tray), robot in workspace looking at it
for vae: 
- input: robot state, camera image
- latent z: robot state, z latent variables
- output: predicted camera image conditioned on robot state

throughout learning will switch object on tray, so (using softmax) it will learn: 
- classification of which object it is based on input
- generative model (for that model) of images conditioned on robot state

Highest complexity state space dim: 
robot state: 6 dimensional (x, y, z, thetax, thetay, thetaz (camera orientation)). 
conditioned on 6dimensional?

* Baby Problems
** 2d Problem
at a set height (y axis in franka world frame), the robot end effector only moves 
in (x,y) plane ((x,z) plane in franka world frame)

orientation options: 
1. orientation is always pointing straight downwards (pi/2, 0, 0)
2. orientation is always pointing towards center of tray 
Note: Don't want to assume that the camera *knows* where the object is, so either point straight 
down or assume that we at least know center orientations
  

*** Starting problem setup 
Setup: object in tray, robot at set height and set orientation straight down

input: robot state and camera image view
latent z: robot state and latent z variable
output: predicted camera image view

Question: Can it learn to reconstruct camera image over entire workspace (conditioned on robot state)?
- will latent variable entropy center on object location (where output image won't just be a plain
image anymore
Note: may need to tune workspace boundaries, otherwise edges of tray may also be hotspots---
may not be a bad thing necessarily

*** Next step: 
- try orientation always at center of tray? (so object images are 
more than just top of it)?
 
*** Next Step: 
- then, try replacing object with different objects (maybe every 100 steps randomly generate new
object in center) 

Setup: object in center of tray, robot at set height and set orientation straight down

input: robot state and camera image view
latent z: robot state and latent z variable
output: predicted camera image view

Question: Can it learn to discriminate different objects?


** Things to consider/investigate todos
*** reduce dimensionality of output by averaging the three channels (so its intensity instead)
** Coding Notes
- To delete existing object and replace with new object (for training new object): use removeBody
- To move robot to different position instantaneously (i.e., for random sampling): use resetBasePositionAndOrientation
*** check out torch layers for making network
